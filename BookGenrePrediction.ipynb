{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BookGenrePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaD+aXCVWdx9P2iOgBfW6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirsho1997/Book-Genre-Prediction-using-Book-Summary/blob/master/BookGenrePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vPi3497tnC5r"
      },
      "source": [
        "**The aim of this project is to apply the principles of text mining on a piece of literary text, and categorize it into the genre into which it best fits.**\n",
        "\n",
        "\n",
        "At the very begining we have to **import all the necessary packages**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-xt4t4z335u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing libraries.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x5llVwLoLJ8",
        "colab_type": "text"
      },
      "source": [
        "The dataset that have been used here is a subset of the **CMU Book Summary Dataset** available at http://www.cs.cmu.edu/~dbamman/booksummaries.html .\n",
        "Dataset was unevenly distributed at the beginning. After day's of data wrangling we could attain some uniformity in the dataset. The processed dataset has been uploaded as BookDataSet.csv , which has **6 main genres** - **\"Crime Fiction\", \"Fanstasy\", \"Historical novel\", \"Horror\", \"Science Fiction\", \"Thriller\"**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6A04T5Z365W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Uploading the dataset on the google colab.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93_Q4fGZ4UX-",
        "colab_type": "text"
      },
      "source": [
        "**Creating the books dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYVG89Qt4TXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using the pandas framework a dataset is created using the \"BooksDataSet.csv\" file.\n",
        "\n",
        "books=pd.read_csv('BooksDataSet.csv')\n",
        "\n",
        "#We only keep the 4 neccessary columns that we will be need. \n",
        "books=pd.DataFrame(books,columns=['book_id','book_name','genre','summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qIIHBW64i_u",
        "colab_type": "text"
      },
      "source": [
        "**Snapshot of how the \"books\" dataframe looks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdYRQ3nT4ooa",
        "colab_type": "code",
        "outputId": "32a93292-be57-46a7-dd29-0dc148891542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#Display the books dataframe\n",
        "books"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>book_name</th>\n",
              "      <th>genre</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3248537</td>\n",
              "      <td>Drowned Wednesday</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>Drowned Wednesday is the first Trustee among ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27796919</td>\n",
              "      <td>The Lost Hero</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>As the book opens, Jason awakens on a school ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3910776</td>\n",
              "      <td>The Eyes of the Overworld</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>Cugel is easily persuaded by the merchant Fia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5969644</td>\n",
              "      <td>Magic's Promise</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>The book opens with Herald-Mage Vanyel return...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3173445</td>\n",
              "      <td>Taran Wanderer</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>Taran and Gurgi have returned to Caer Dallben...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>10372180</td>\n",
              "      <td>White Death</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>A Novel from the NUMA files, A Kurt Austin Ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>14504372</td>\n",
              "      <td>Venus with Pistol</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>Gilbert Kemp is dealer specializing in antiqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>3617412</td>\n",
              "      <td>Blackwater</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>\"How do you know when you're in too deep? Dav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>11320975</td>\n",
              "      <td>The Rainbow and the Rose</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>The story concerns the life of Johnnie Pascoe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>17227674</td>\n",
              "      <td>Chiefs</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>The First Chief: Will Henry Lee: The novel op...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       book_id  ...                                            summary\n",
              "0      3248537  ...   Drowned Wednesday is the first Trustee among ...\n",
              "1     27796919  ...   As the book opens, Jason awakens on a school ...\n",
              "2      3910776  ...   Cugel is easily persuaded by the merchant Fia...\n",
              "3      5969644  ...   The book opens with Herald-Mage Vanyel return...\n",
              "4      3173445  ...   Taran and Gurgi have returned to Caer Dallben...\n",
              "...        ...  ...                                                ...\n",
              "2995  10372180  ...   A Novel from the NUMA files, A Kurt Austin Ad...\n",
              "2996  14504372  ...   Gilbert Kemp is dealer specializing in antiqu...\n",
              "2997   3617412  ...   \"How do you know when you're in too deep? Dav...\n",
              "2998  11320975  ...   The story concerns the life of Johnnie Pascoe...\n",
              "2999  17227674  ...   The First Chief: Will Henry Lee: The novel op...\n",
              "\n",
              "[3000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WllLU2V44s6C",
        "colab_type": "text"
      },
      "source": [
        "**Grouping all the rows by genre**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0rpYJ0Q4rfh",
        "colab_type": "code",
        "outputId": "d209f901-a9c1-4752-f03d-54f33287736b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#We group our dataset by \"genre\" and see that we have 500 rows dedicated to each of the 6 genres.\n",
        "\n",
        "books.groupby('genre').count()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>book_name</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genre</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Crime Fiction</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fantasy</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Historical novel</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horror</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Science Fiction</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thriller</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  book_id  book_name  summary\n",
              "genre                                        \n",
              "Crime Fiction         500        500      500\n",
              "Fantasy               500        500      500\n",
              "Historical novel      500        500      500\n",
              "Horror                500        500      500\n",
              "Science Fiction       500        500      500\n",
              "Thriller              500        500      500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlVswdX645U-",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing the \"summary\" column and making it ready for prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QFK2Cxa5Aks",
        "colab_type": "text"
      },
      "source": [
        "1) Filtering out any character which is not an alphabet and then converting each character into lowercase from column 'summary'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnto4bQG4-9a",
        "colab_type": "code",
        "outputId": "d26f8f59-63e7-4b11-f484-cbf1ef4597b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "books['summary']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Drowned Wednesday is the first Trustee among ...\n",
              "1        As the book opens, Jason awakens on a school ...\n",
              "2        Cugel is easily persuaded by the merchant Fia...\n",
              "3        The book opens with Herald-Mage Vanyel return...\n",
              "4        Taran and Gurgi have returned to Caer Dallben...\n",
              "                              ...                        \n",
              "2995     A Novel from the NUMA files, A Kurt Austin Ad...\n",
              "2996     Gilbert Kemp is dealer specializing in antiqu...\n",
              "2997     \"How do you know when you're in too deep? Dav...\n",
              "2998     The story concerns the life of Johnnie Pascoe...\n",
              "2999     The First Chief: Will Henry Lee: The novel op...\n",
              "Name: summary, Length: 3000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1fAUxFy5yj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for text cleaning \n",
        "def clean(text):\n",
        "    # remove backslash-apostrophe \n",
        "    text = re.sub(\"\\'\", \"\", text) \n",
        "    # remove everything except alphabets \n",
        "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
        "    # remove whitespaces \n",
        "    text = ' '.join(text.split()) \n",
        "    # convert text to lowercase \n",
        "    text = text.lower() \n",
        "    \n",
        "    return text\n",
        "\n",
        "books.loc[:,'summary']=books.loc[:,'summary'].apply(lambda x: clean(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB1nPgLu54q_",
        "colab_type": "code",
        "outputId": "bc6ddf8e-cc9d-4c27-c369-66de99b15651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Displaying \"summary\" after text-cleaning\n",
        "books['summary']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       drowned wednesday is the first trustee among t...\n",
              "1       as the book opens jason awakens on a school bu...\n",
              "2       cugel is easily persuaded by the merchant fian...\n",
              "3       the book opens with herald mage vanyel returni...\n",
              "4       taran and gurgi have returned to caer dallben ...\n",
              "                              ...                        \n",
              "2995    a novel from the numa files a kurt austin adve...\n",
              "2996    gilbert kemp is dealer specializing in antique...\n",
              "2997    how do you know when youre in too deep davey h...\n",
              "2998    the story concerns the life of johnnie pascoe ...\n",
              "2999    the first chief will henry lee the novel opens...\n",
              "Name: summary, Length: 3000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X--_NH8A57IO",
        "colab_type": "text"
      },
      "source": [
        "2) **Removing stop words** from the column summary.\n",
        "\n",
        "Another part of data cleaning is the **removal of stop words** – that is, common words like “the”, “a”, “an”. They are assumed to have no consequence over the classification process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meg_agBl6UIT",
        "colab_type": "code",
        "outputId": "33bbf9af-10e9-49a8-c214-45be78b47ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
        "    return ' '.join(no_stopword_text)\n",
        "\n",
        "books['summary'] = books['summary'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy6PdiAN6Z69",
        "colab_type": "code",
        "outputId": "f6917d8c-697f-4c64-e268-67628cb9dfe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Displaying \"summary\" after removing stop words\n",
        "books['summary']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       drowned wednesday first trustee among morrow d...\n",
              "1       book opens jason awakens school bus unable rem...\n",
              "2       cugel easily persuaded merchant fianosther att...\n",
              "3       book opens herald mage vanyel returning countr...\n",
              "4       taran gurgi returned caer dallben following ev...\n",
              "                              ...                        \n",
              "2995    novel numa files kurt austin adventure novel m...\n",
              "2996    gilbert kemp dealer specializing antique guns ...\n",
              "2997    know youre deep davey always lived shadow olde...\n",
              "2998    story concerns life johnnie pascoe retired com...\n",
              "2999    first chief henry lee novel opens growing town...\n",
              "Name: summary, Length: 3000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBVohHje6hvj",
        "colab_type": "text"
      },
      "source": [
        "3) **Lemmatization** on 'summary'\n",
        "\n",
        "Greater the degree of randomness, greater would be the computation time, and lesser would be the efficiency of the detection of patterns in the textual corpora. We introduced the module which performs lemmatization on words, that is, **it groups different versions of the same word into one – for example, “do/doing/does/did”, “go/going/goes/went”** – so as to not let the algorithm treat similar words as different, and hence, make the analysis stronger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQSjS2Y6eVX",
        "colab_type": "code",
        "outputId": "5d94dc6b-0325-4937-a0c0-a02667140418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemma=WordNetLemmatizer()\n",
        "\n",
        "def lematizing(sentence):\n",
        "    stemSentence = \"\"\n",
        "    for word in sentence.split():\n",
        "        stem = lemma.lemmatize(word)\n",
        "        stemSentence += stem\n",
        "        stemSentence += \" \"\n",
        "    stemSentence = stemSentence.strip()\n",
        "    return stemSentence\n",
        "\n",
        "\n",
        "books['summary'] = books['summary'].apply(lambda x: lematizing(x))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ShvZYCP6rHO",
        "colab_type": "code",
        "outputId": "4f46c2aa-45ad-4810-f5a5-4f7a09807b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Displaying \"summary\" after Lemmmatization\n",
        "books['summary']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       drowned wednesday first trustee among morrow d...\n",
              "1       book open jason awakens school bus unable reme...\n",
              "2       cugel easily persuaded merchant fianosther att...\n",
              "3       book open herald mage vanyel returning country...\n",
              "4       taran gurgi returned caer dallben following ev...\n",
              "                              ...                        \n",
              "2995    novel numa file kurt austin adventure novel ma...\n",
              "2996    gilbert kemp dealer specializing antique gun l...\n",
              "2997    know youre deep davey always lived shadow olde...\n",
              "2998    story concern life johnnie pascoe retired comm...\n",
              "2999    first chief henry lee novel open growing town ...\n",
              "Name: summary, Length: 3000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC1mKYe1RWjV",
        "colab_type": "text"
      },
      "source": [
        "4) **Stemming** on 'summary'\n",
        "\n",
        "**Stemming is the process of producing morphological variants of a root/base word.** Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces **the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3cXXPyIRUWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "def stemming(sentence):\n",
        "    stemSentence = \"\"\n",
        "    for word in sentence.split():\n",
        "        stem = stemmer.stem(word)\n",
        "        stemSentence += stem\n",
        "        stemSentence += \" \"\n",
        "    stemSentence = stemSentence.strip()\n",
        "    return stemSentence\n",
        "\n",
        "\n",
        "books['summary'] = books['summary'].apply(lambda x: stemming(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg6xu-CnRrjc",
        "colab_type": "code",
        "outputId": "52113ba1-1259-479d-e8d3-541c7582b0c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Displaying \"summary\" after Stemming\n",
        "books['summary']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       drown wednesday first truste among morrow day ...\n",
              "1       book open jason awaken school bu unabl rememb ...\n",
              "2       cugel easili persuad merchant fianosth attempt...\n",
              "3       book open herald mage vanyel return countri va...\n",
              "4       taran gurgi return caer dallben follow event t...\n",
              "                              ...                        \n",
              "2995    novel numa file kurt austin adventur novel mai...\n",
              "2996    gilbert kemp dealer special antiqu gun london ...\n",
              "2997    know your deep davey alway live shadow older b...\n",
              "2998    stori concern life johnni pasco retir commerci...\n",
              "2999    first chief henri lee novel open grow town del...\n",
              "Name: summary, Length: 3000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qon_nj2u3nI",
        "colab_type": "text"
      },
      "source": [
        "Now, we **denote an unique number to each of the 6 genres** from 0 - 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ7Zy8chSCbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Labeling each 'genre' with an unique number \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "\n",
        "y=LE.fit_transform(books['genre'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87lDyg7rvgGZ",
        "colab_type": "text"
      },
      "source": [
        "The mapping is 1:1\n",
        "\n",
        "**Crime Fiction    -  0**\n",
        "\n",
        "**Fantasy          -  1**\n",
        "\n",
        "**Historical novel -  2**\n",
        "\n",
        "**Horror           -  3**\n",
        "\n",
        "**Science Fiction  -  4**\n",
        "\n",
        "**Thriller         -  5** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IADBUHXGSD-K",
        "colab_type": "code",
        "outputId": "c5a58ee5-46e1-433d-d1f0-5fa36ad3b49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#perform inverse mapping on the unique numbers representing a genre.\n",
        "LE.inverse_transform([0,1,2,3,4,5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Crime Fiction', 'Fantasy', 'Historical novel', 'Horror',\n",
              "       'Science Fiction', 'Thriller'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN9yti7-SZ9Q",
        "colab_type": "text"
      },
      "source": [
        "At first a **80-20% split** was performed on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvoMPaTFSZC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xval, ytrain, yval = train_test_split(books['summary'], y, test_size=0.2, random_state=557) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNSXRDGZxQEW",
        "colab_type": "text"
      },
      "source": [
        "**tf-idf was performed on \"summary\" for both train(i.e xtrain) and test(i.e xval).**\n",
        "\n",
        "**tf–idf** or TFIDF, short for **term frequency–inverse document frequency**, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
        "\n",
        "\n",
        "**tf(t)** = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
        "\n",
        "**idf(t)** = log_e(Total number of documents / Number of documents with term t in it)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJXZoVHCStjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Performing tf-idf \n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
        "\n",
        "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain.values.astype('U'))\n",
        "\n",
        "xval_tfidf = tfidf_vectorizer.transform(xval.values.astype('U'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA7CVZjQTcLO",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "Logistic Regression is used when the **dependent variable( target ) is categorical**.\n",
        "\n",
        "logistic regressions are only binary classifiers, meaning they cannot handle target vectors with more than two classes. However, there are clever extensions to logistic regression to do just that. In one-vs-rest logistic regression (OVR) a separate model is trained for each class predicted whether an observation is that class or not (thus making it a binary classification problem). It assumes that each classification problem (e.g. class 0 or not) is independent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3_HstvETg80",
        "colab_type": "code",
        "outputId": "1591f334-3305-4c54-bc7f-177f8fcbec01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Binary Relevance.\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Performance metric.\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "clf = OneVsRestClassifier(lr)\n",
        "\n",
        "# fit model on train data.\n",
        "clf.fit(xtrain_tfidf, ytrain)\n",
        "\n",
        "# make predictions for validation set.\n",
        "y_pred_lr = clf.predict(xval_tfidf)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "  \n",
        "\n",
        "#Calculating the accuracy.\n",
        "print( 'Accuracy Score :',accuracy_score(yval,y_pred_lr) )\n",
        "\n",
        "#Printing the classification report.\n",
        "print ('Report : ')\n",
        "print(classification_report(yval,y_pred_lr))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.7833333333333333\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.80       102\n",
            "           1       0.70      0.78      0.74        89\n",
            "           2       0.82      0.86      0.84       110\n",
            "           3       0.78      0.73      0.76       100\n",
            "           4       0.81      0.80      0.81        97\n",
            "           5       0.79      0.70      0.74       102\n",
            "\n",
            "    accuracy                           0.78       600\n",
            "   macro avg       0.78      0.78      0.78       600\n",
            "weighted avg       0.78      0.78      0.78       600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snW-sIMPT8l8",
        "colab_type": "text"
      },
      "source": [
        "**--SVM('linear')--**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq-xzxitT2C-",
        "colab_type": "code",
        "outputId": "6f0cc26c-d300-4ab0-c7bf-6aec6c2e6f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svc = svm.SVC(kernel='linear').fit(xtrain_tfidf,ytrain)\n",
        "\n",
        "svpred=svc.predict(xval_tfidf)\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "  \n",
        "\n",
        "\n",
        "print( 'Accuracy Score :',accuracy_score(yval,svpred) )\n",
        "print ('Report : ')\n",
        "print(classification_report(yval,svpred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.7616666666666667\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.77      0.79       102\n",
            "           1       0.69      0.73      0.71        89\n",
            "           2       0.82      0.86      0.84       110\n",
            "           3       0.73      0.74      0.74       100\n",
            "           4       0.80      0.74      0.77        97\n",
            "           5       0.71      0.71      0.71       102\n",
            "\n",
            "    accuracy                           0.76       600\n",
            "   macro avg       0.76      0.76      0.76       600\n",
            "weighted avg       0.76      0.76      0.76       600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUeED80DUmtp",
        "colab_type": "text"
      },
      "source": [
        "**--SVM(kernel=rbf)--**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuUia4CgUMLu",
        "colab_type": "code",
        "outputId": "d14b7e12-1d55-42a0-f2c5-f94bd3063527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svc = svm.SVC(kernel='rbf',gamma=1).fit(xtrain_tfidf,ytrain)\n",
        "\n",
        "svpred=svc.predict(xval_tfidf)\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "  \n",
        "\n",
        "\n",
        "print( 'Accuracy Score :',accuracy_score(yval,svpred) )\n",
        "print ('Report : ')\n",
        "print(classification_report(yval,svpred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.7766666666666666\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.81       102\n",
            "           1       0.68      0.75      0.71        89\n",
            "           2       0.83      0.85      0.84       110\n",
            "           3       0.78      0.74      0.76       100\n",
            "           4       0.83      0.77      0.80        97\n",
            "           5       0.71      0.75      0.73       102\n",
            "\n",
            "    accuracy                           0.78       600\n",
            "   macro avg       0.78      0.78      0.78       600\n",
            "weighted avg       0.78      0.78      0.78       600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9nhoUt9U1ej",
        "colab_type": "text"
      },
      "source": [
        "**Now we try with a 85-15% split on the dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aTV3SYGRVHcV",
        "colab": {}
      },
      "source": [
        "xtrain, xval, ytrain, yval = train_test_split(books['summary'], y, test_size=0.15, random_state=246) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pXfgO82LVHch"
      },
      "source": [
        "**Performing tf-idf on 'summary' for both train(i.e xtrain) and test(i.e xval)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mvc2lXf7VHci",
        "colab": {}
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
        "\n",
        "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain.values.astype('U'))\n",
        "\n",
        "xval_tfidf = tfidf_vectorizer.transform(xval.values.astype('U'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WKEDAHZLVHcp"
      },
      "source": [
        "**--Logistic Regression--**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "05358a6f-7d88-4d24-8ca8-712c94b409d2",
        "id": "W40w1rctVHcq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Binary Relevance\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Performance metric\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lr = LogisticRegression()\n",
        "clf = OneVsRestClassifier(lr)\n",
        "\n",
        "# fit model on train data\n",
        "clf.fit(xtrain_tfidf, ytrain)\n",
        "\n",
        "# make predictions for validation set\n",
        "y_pred_lr = clf.predict(xval_tfidf)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "  \n",
        "\n",
        "\n",
        "print( 'Accuracy Score :',accuracy_score(yval,y_pred_lr) )\n",
        "print ('Report : ')\n",
        "print(classification_report(yval,y_pred_lr))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.78\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.78      0.75        67\n",
            "           1       0.79      0.83      0.81        82\n",
            "           2       0.85      0.85      0.85        86\n",
            "           3       0.73      0.72      0.73        72\n",
            "           4       0.82      0.86      0.84        64\n",
            "           5       0.75      0.65      0.69        79\n",
            "\n",
            "    accuracy                           0.78       450\n",
            "   macro avg       0.78      0.78      0.78       450\n",
            "weighted avg       0.78      0.78      0.78       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s89TbYoWVHc0"
      },
      "source": [
        "**--KNN--**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ecbef845-c791-4056-f7f7-aa67e14fcfb3",
        "id": "VhvtxQO6VHc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier(n_neighbors=65) #2000\n",
        "\n",
        "knn.fit(xtrain_tfidf,ytrain)\n",
        "\n",
        "knnop=knn.predict(xval_tfidf)\n",
        "# Performance metric\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "  \n",
        "\n",
        "\n",
        "print( 'Accuracy Score :',accuracy_score(yval,knnop) )\n",
        "print ('Report : ')\n",
        "print(classification_report(yval,knnop))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.6777777777777778\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.72      0.67        67\n",
            "           1       0.78      0.65      0.71        82\n",
            "           2       0.66      0.78      0.72        86\n",
            "           3       0.59      0.61      0.60        72\n",
            "           4       0.72      0.88      0.79        64\n",
            "           5       0.71      0.47      0.56        79\n",
            "\n",
            "    accuracy                           0.68       450\n",
            "   macro avg       0.68      0.68      0.67       450\n",
            "weighted avg       0.68      0.68      0.67       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7M3o4A3ZVHc-"
      },
      "source": [
        "**--SVM('linear')--**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "421ee652-dce7-4e9b-c7d4-c5d01505c111",
        "id": "wbRRtTt6VHdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svc = svm.SVC(kernel='linear').fit(xtrain_tfidf,ytrain)\n",
        "\n",
        "svpred=svc.predict(xval_tfidf)\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "  \n",
        "\n",
        "\n",
        "print( 'Accuracy Score :',accuracy_score(yval,svpred) )\n",
        "print ('Report : ')\n",
        "print(classification_report(yval,svpred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.78\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.75      0.75        67\n",
            "           1       0.78      0.83      0.80        82\n",
            "           2       0.85      0.84      0.84        86\n",
            "           3       0.70      0.74      0.72        72\n",
            "           4       0.84      0.83      0.83        64\n",
            "           5       0.75      0.70      0.72        79\n",
            "\n",
            "    accuracy                           0.78       450\n",
            "   macro avg       0.78      0.78      0.78       450\n",
            "weighted avg       0.78      0.78      0.78       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KiqCESu_VHdG"
      },
      "source": [
        "**--SVM(kernel=rbf)--**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5db96460-5cc2-4628-8677-e2fa53a8d1e9",
        "id": "aH7sPT76VHdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svc = svm.SVC(kernel='rbf',gamma=1).fit(xtrain_tfidf,ytrain)\n",
        "\n",
        "svpred=svc.predict(xval_tfidf)\n",
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "  \n",
        "\n",
        "\n",
        "print( 'Accuracy Score :',accuracy_score(yval,svpred) )\n",
        "print ('Report : ')\n",
        "print(classification_report(yval,svpred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.7955555555555556\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.76      0.77        67\n",
            "           1       0.80      0.88      0.84        82\n",
            "           2       0.86      0.85      0.85        86\n",
            "           3       0.73      0.74      0.73        72\n",
            "           4       0.86      0.86      0.86        64\n",
            "           5       0.75      0.68      0.72        79\n",
            "\n",
            "    accuracy                           0.80       450\n",
            "   macro avg       0.79      0.79      0.79       450\n",
            "weighted avg       0.80      0.80      0.79       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUaAEfXaVpIC",
        "colab_type": "text"
      },
      "source": [
        "**--Executing the inference function on SVM(kernel=rbf) to predict future unknown genre--**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzL-eMalVooL",
        "colab_type": "code",
        "outputId": "b413b82d-f1ec-471a-c7d3-4a165f7bee1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "def infer_tags(q):\n",
        "    q = clean(q)\n",
        "    q = remove_stopwords(q)\n",
        "    q = lematizing(q)\n",
        "    q = stemming(q)\n",
        "    q_vec = tfidf_vectorizer.transform([q])\n",
        "    q_pred = svc.predict(q_vec)\n",
        "    return LE.inverse_transform(q_pred)[0]\n",
        "    #return q_pred[0]\n",
        "\n",
        "\n",
        "for i in range(10): \n",
        "  k = xval.sample(1).index[0] \n",
        "  print(\"Book: \", books['book_name'][k], \"\\nPredicted genre: \", infer_tags(xval[k]),\"\\nActual genre: \",books['genre'][k], \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Book:  The Burning Land \n",
            "Predicted genre:  Historical novel \n",
            "Actual genre:  Historical novel \n",
            "\n",
            "Book:  The Starlight Barking \n",
            "Predicted genre:  Fantasy \n",
            "Actual genre:  Fantasy \n",
            "\n",
            "Book:  The Black Prism \n",
            "Predicted genre:  Fantasy \n",
            "Actual genre:  Fantasy \n",
            "\n",
            "Book:  Necroscope V: Deadspawn \n",
            "Predicted genre:  Horror \n",
            "Actual genre:  Horror \n",
            "\n",
            "Book:  The Doomsday Conspiracy \n",
            "Predicted genre:  Thriller \n",
            "Actual genre:  Thriller \n",
            "\n",
            "Book:  The Letter of Marque \n",
            "Predicted genre:  Historical novel \n",
            "Actual genre:  Historical novel \n",
            "\n",
            "Book:  The Dain Curse \n",
            "Predicted genre:  Crime Fiction \n",
            "Actual genre:  Crime Fiction \n",
            "\n",
            "Book:  The Seekers \n",
            "Predicted genre:  Historical novel \n",
            "Actual genre:  Historical novel \n",
            "\n",
            "Book:  The Brimstone Wedding \n",
            "Predicted genre:  Thriller \n",
            "Actual genre:  Crime Fiction \n",
            "\n",
            "Book:  Firestarter \n",
            "Predicted genre:  Horror \n",
            "Actual genre:  Horror \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}